{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1mIQ7ej_nzws"},"outputs":[],"source":["!pip install openai-whisper"]},{"cell_type":"code","source":["import os\n","import whisper"],"metadata":{"id":"PUf00Au3J2jn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["audio_folder_path = \"/content/drive/MyDrive/Maestria/Deep Learning/01. Whisper/data/audio/\"\n","\n","# 'tiny', 'base', 'small', 'medium', 'large'\n","model = whisper.load_model(\"base\")\n","\n","audio_files = [f for f in os.listdir(audio_folder_path) if f.endswith('.mp3')]\n","\n","for audio_file in audio_files:\n","    audio_file_path = os.path.join(audio_folder_path, audio_file)\n","    result = model.transcribe(audio_file_path, language=\"es\")\n","    transcript_output_path = os.path.join(audio_folder_path, f\"{os.path.splitext(audio_file)[0]}.txt\")\n","    with open(transcript_output_path, \"w\") as file:\n","        file.write(result[\"text\"])\n","\n","    print(f\"Transcripción guardada exitosamente: {transcript_output_path}\")\n","\n","print(\"Proceso de transcripción completado.\")\n"],"metadata":{"id":"SNmcSv2eI46a"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8XNJ5I+XCejJG4B1ALZBv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}